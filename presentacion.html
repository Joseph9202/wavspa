<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>presentacion_wavspa_univalle</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/theme/black.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section id="wavspa-wavelet-space-attention" class="slide level1">
<h1>WavSpA: Wavelet Space Attention</h1>
<h2 id="transformers-eficientes-mediante-anÃ¡lisis-multi-escala">Transformers Eficientes mediante AnÃ¡lisis Multi-Escala</h2>
<p><strong>Seminario del Departamento de MatemÃ¡ticas</strong><br />
Universidad del Valle<br />
Octubre 2025</p>
</section>
<section class="slide level1">

<h2 id="agenda">ğŸ“‹ Agenda</h2>
<ol type="1">
<li><strong>MotivaciÃ³n</strong>: El problema de las secuencias largas</li>
<li><strong>Fundamentos MatemÃ¡ticos</strong>: TeorÃ­a de Wavelets</li>
<li><strong>Arquitectura WavSpA</strong>: DiseÃ±o e ImplementaciÃ³n</li>
<li><strong>AnÃ¡lisis TeÃ³rico</strong>: Complejidad y Propiedades</li>
<li><strong>Resultados Experimentales</strong>: Long Range Arena</li>
<li><strong>CÃ³digo</strong>: AnÃ¡lisis de ImplementaciÃ³n</li>
<li><strong>Conclusiones y Trabajo Futuro</strong></li>
</ol>
</section>
<section id="motivaciÃ³n" class="slide level1">
<h1>1. MotivaciÃ³n</h1>
</section>
<section class="slide level1">

<h2 id="el-problema-complejidad-cuadrÃ¡tica-en-transformers">El Problema: Complejidad CuadrÃ¡tica en Transformers</h2>
<h3 id="transformer-estÃ¡ndar-vaswani-et-al.-2017">Transformer EstÃ¡ndar (Vaswani et al., 2017)</h3>
<p><strong>Mecanismo de AtenciÃ³n:</strong></p>
<p><span class="math display">$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$</span></p>
<p>donde: - <span class="math inline"><em>Q</em>,â€†<em>K</em>,â€†<em>V</em>â€„âˆˆâ€„â„<sup><em>L</em>â€…Ã—â€…<em>d</em></sup></span> (Queries, Keys, Values) - <span class="math inline"><em>L</em></span> = longitud de secuencia - <span class="math inline"><em>d</em></span> = dimensiÃ³n de embedding</p>
</section>
<section class="slide level1">

<h2 id="anÃ¡lisis-de-complejidad">AnÃ¡lisis de Complejidad</h2>
<h3 id="producto-matricial-qkt">Producto Matricial <span class="math inline"><em>Q</em><em>K</em><sup><em>T</em></sup></span>:</h3>
<p><span class="math display"><em>Q</em><em>K</em><sup><em>T</em></sup>â€„âˆˆâ€„â„<sup><em>L</em>â€…Ã—â€…<em>L</em></sup></span></p>
<p><strong>Complejidad Computacional:</strong> - Tiempo: <span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>â€…â‹…â€…<em>d</em>)</span> - Memoria: <span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>)</span></p>
<p><strong>Problema:</strong> - <span class="math inline"><em>L</em>â€„=â€„512</span>: ~260K operaciones - <span class="math inline"><em>L</em>â€„=â€„4096</span>: ~16M operaciones (61Ã— mÃ¡s!) - <span class="math inline"><em>L</em>â€„=â€„16384</span>: ~268M operaciones (1000Ã— mÃ¡s!)</p>
<p>âŒ <strong>No escalable</strong> para secuencias largas</p>
</section>
<section class="slide level1">

<h2 id="aplicaciones-requieren-secuencias-largas">Aplicaciones Requieren Secuencias Largas</h2>
<table>
<thead>
<tr class="header">
<th>Tarea</th>
<th>Longitud TÃ­pica</th>
<th>DesafÃ­o</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Resumen de documentos</td>
<td>4K-16K tokens</td>
<td>Capturar narrativa completa</td>
</tr>
<tr class="even">
<td>AnÃ¡lisis de cÃ³digo</td>
<td>8K-32K tokens</td>
<td>Dependencias de largo alcance</td>
</tr>
<tr class="odd">
<td>GenÃ³mica</td>
<td>100K-1M bases</td>
<td>Patrones regulatorios distantes</td>
</tr>
<tr class="even">
<td>Series temporales</td>
<td>10K-100K puntos</td>
<td>Tendencias de largo plazo</td>
</tr>
<tr class="odd">
<td>Audio/Video</td>
<td>48K-192K frames</td>
<td>Coherencia temporal</td>
</tr>
</tbody>
</table>
<p><strong>Necesidad:</strong> Modelos eficientes para <span class="math inline"><em>L</em>â€„â‰«â€„4096</span></p>
</section>
<section id="fundamentos-matemÃ¡ticos" class="slide level1">
<h1>2. Fundamentos MatemÃ¡ticos</h1>
</section>
<section class="slide level1">

<h2 id="teorÃ­a-de-wavelets-intuiciÃ³n">TeorÃ­a de Wavelets: IntuiciÃ³n</h2>
<h3 id="quÃ©-es-una-wavelet">Â¿QuÃ© es una Wavelet?</h3>
<p>Una <strong>wavelet</strong> <span class="math inline"><em>Ïˆ</em>(<em>t</em>)</span> es una â€œonditaâ€ localizada:</p>
<p><span class="math display">âˆ«<sub>â€…âˆ’â€…âˆ</sub><sup>âˆ</sup><em>Ïˆ</em>(<em>t</em>)â€†<em>d</em><em>t</em>â€„=â€„0â€Šâ€(media cero)</span></p>
<p><span class="math display">âˆ«<sub>â€…âˆ’â€…âˆ</sub><sup>âˆ</sup>|<em>Ïˆ</em>(<em>t</em>)|<sup>2</sup>â€†<em>d</em><em>t</em>â€„&lt;â€„âˆâ€Šâ€(energÃ­a finita)</span></p>
<p><strong>Familia de Wavelets:</strong></p>
<p><span class="math display">$$
\psi_{a,b}(t) = \frac{1}{\sqrt{|a|}} \psi\left(\frac{t-b}{a}\right)
$$</span></p>
<ul>
<li><span class="math inline"><em>a</em></span>: escala (frecuencia)</li>
<li><span class="math inline"><em>b</em></span>: translaciÃ³n (posiciÃ³n)</li>
</ul>
</section>
<section class="slide level1">

<h2 id="transformada-wavelet-anÃ¡lisis-multi-escala">Transformada Wavelet: AnÃ¡lisis Multi-Escala</h2>
<h3 id="transformada-wavelet-continua-cwt">Transformada Wavelet Continua (CWT):</h3>
<p><span class="math display">$$
W_f(a, b) = \int_{-\infty}^{\infty} f(t) \, \frac{1}{\sqrt{|a|}} \psi^*\left(\frac{t-b}{a}\right) dt
$$</span></p>
<p><strong>InterpretaciÃ³n:</strong> - Mide similitud entre seÃ±al <span class="math inline"><em>f</em>(<em>t</em>)</span> y wavelet en escala <span class="math inline"><em>a</em></span>, posiciÃ³n <span class="math inline"><em>b</em></span> - Plano tiempo-frecuencia: <span class="math inline">(<em>b</em>,â€†<em>a</em>)â€„â†¦â€„<em>W</em><sub><em>f</em></sub>(<em>a</em>,â€†<em>b</em>)</span></p>
<h3 id="transformada-wavelet-discreta-dwt">Transformada Wavelet Discreta (DWT):</h3>
<p><span class="math display"><em>c</em><sub><em>j</em></sub>[<em>k</em>]â€„=â€„âˆ‘<sub><em>n</em></sub><em>f</em>[<em>n</em>]â€†<em>h</em><sub><em>j</em></sub>[2<sup><em>j</em></sup><em>k</em>â€…âˆ’â€…<em>n</em>]</span></p>
<p><strong>Banco de Filtros:</strong> - <span class="math inline"><em>h</em><sub>0</sub></span>: filtro paso-bajo (aproximaciÃ³n) - <span class="math inline"><em>h</em><sub>1</sub></span>: filtro paso-alto (detalles)</p>
</section>
<section class="slide level1">

<h2 id="descomposiciÃ³n-multi-resoluciÃ³n">DescomposiciÃ³n Multi-ResoluciÃ³n</h2>
<h3 id="esquema-de-descomposiciÃ³n-3-niveles">Esquema de DescomposiciÃ³n (3 niveles):</h3>
<pre><code>SeÃ±al Original [L puntos]
        |
        â”œâ”€ [h0] â†’ AproximaciÃ³n Aâ‚ [L/2] â”€â”€â”
        |                                  |
        â””â”€ [h1] â†’ Detalle Dâ‚ [L/2]         |
                                           |
                  Aâ‚ [L/2]                 |
                    |                      |
                    â”œâ”€ [h0] â†’ Aâ‚‚ [L/4] â”€â”€â”€â”€â”¤
                    |                      |
                    â””â”€ [h1] â†’ Dâ‚‚ [L/4]     |
                                           |
                        Aâ‚‚ [L/4]           |
                          |                |
                          â”œâ”€ [h0] â†’ Aâ‚ƒ [L/8]
                          |
                          â””â”€ [h1] â†’ Dâ‚ƒ [L/8]

Resultado: {Aâ‚ƒ, Dâ‚ƒ, Dâ‚‚, Dâ‚}</code></pre>
<p><strong>Propiedad Clave:</strong> ReconstrucciÃ³n perfecta <span class="math display"><em>f</em>â€„=â€„IDWT(DWT(<em>f</em>))</span></p>
</section>
<section class="slide level1">

<h2 id="wavelets-de-daubechies">Wavelets de Daubechies</h2>
<h3 id="construcciÃ³n-de-daubechies-orden-n">ConstrucciÃ³n de Daubechies (orden <span class="math inline"><em>N</em></span>):</h3>
<p><strong>Problema:</strong> Encontrar <span class="math inline"><em>h</em><sub>0</sub>â€„=â€„[<em>h</em><sub>0</sub>,â€†<em>h</em><sub>1</sub>,â€†â€¦,â€†<em>h</em><sub>2<em>N</em>â€…âˆ’â€…1</sub>]</span> tal que:</p>
<ol type="1">
<li><p><strong>Ortogonalidad:</strong> <span class="math display">âˆ‘<sub><em>k</em></sub><em>h</em><sub>0</sub>[<em>k</em>]<em>h</em><sub>0</sub>[<em>k</em>â€…âˆ’â€…2<em>m</em>]â€„=â€„<em>Î´</em><sub><em>m</em></sub></span></p></li>
<li><p><strong>Momentos Nulos:</strong> <span class="math display">âˆ‘<sub><em>k</em></sub><em>k</em><sup><em>p</em></sup><em>h</em><sub>1</sub>[<em>k</em>]â€„=â€„0,â€Šâ€<em>p</em>â€„=â€„0,â€†1,â€†â€¦,â€†<em>N</em>â€…âˆ’â€…1</span></p></li>
<li><p><strong>NormalizaciÃ³n:</strong> <span class="math display">$$
\sum_k h_0[k] = \sqrt{2}
$$</span></p></li>
</ol>
<p><strong>SoluciÃ³n:</strong> FactorizaciÃ³n de FejÃ©r-Riesz del polinomio:</p>
<p><span class="math display">$$
P(\omega) = \left(\frac{1 + e^{i\omega}}{2}\right)^N Q(\omega)
$$</span></p>
<p>donde <span class="math inline"><em>Q</em>(<em>Ï‰</em>)</span> tiene raÃ­ces especÃ­ficas.</p>
</section>
<section class="slide level1">

<h2 id="visualizaciÃ³n-db2-db4-db8">VisualizaciÃ³n: db2, db4, db8</h2>
<h3 id="daubechies-orden-2-db2">Daubechies orden 2 (db2):</h3>
<pre><code>Filtro: [âˆ’0.129, 0.224, 0.836, 0.483]
Soporte: 4 coeficientes</code></pre>
<h3 id="daubechies-orden-4-db4">Daubechies orden 4 (db4):</h3>
<pre><code>Filtro: [âˆ’0.010, âˆ’0.132, 0.047, 0.787, 0.607, âˆ’0.165, âˆ’0.072, 0.020]
Soporte: 8 coeficientes
Suavidad: â†‘â†‘</code></pre>
<h3 id="daubechies-orden-8-db8">Daubechies orden 8 (db8):</h3>
<pre><code>Soporte: 16 coeficientes
Suavidad: â†‘â†‘â†‘â†‘</code></pre>
<p><strong>Trade-off:</strong> MÃ¡s suavidad â†”ï¸ MÃ¡s soporte (menos localizaciÃ³n)</p>
</section>
<section id="arquitectura-wavspa" class="slide level1">
<h1>3. Arquitectura WavSpA</h1>
</section>
<section class="slide level1">

<h2 id="idea-central-atenciÃ³n-en-dominio-wavelet">Idea Central: AtenciÃ³n en Dominio Wavelet</h2>
<h3 id="pipeline-completo">Pipeline Completo:</h3>
<pre><code>Input Sequence x âˆˆ â„^(BÃ—LÃ—D)
        â†“
   [LayerNorm]
        â†“
   [Wavelet Forward Transform]
        â†“
   {zâ‚€, zâ‚, zâ‚‚, ..., z_J}
   [L/1] [L/2] [L/4]    [L/2^J]
        â†“    â†“    â†“         â†“
   [Attn] [Attn] [Attn] ... [Attn]
        â†“    â†“    â†“         â†“
   {z&#39;â‚€, z&#39;â‚, z&#39;â‚‚, ..., z&#39;_J}
        â†“
   [Wavelet Inverse Transform]
        â†“
   x&#39; âˆˆ â„^(BÃ—LÃ—D)
        â†“
   [x + x&#39;] (Residual)
        â†“
   [MLP Block]
        â†“
   Output</code></pre>
<p><strong>IntuiciÃ³n:</strong> Procesar diferentes escalas con diferentes â€œventanas de contextoâ€</p>
</section>
<section class="slide level1">

<h2 id="matemÃ¡tica-formal-descomposiciÃ³n">MatemÃ¡tica Formal: DescomposiciÃ³n</h2>
<h3 id="forward-transform-j-niveles">Forward Transform (J niveles):</h3>
<p><span class="math display">$$
\begin{align}
z_0^{(0)} &amp;= x \\
z_j^{(k+1)} &amp;= (z_j^{(k)} * h_0) \downarrow 2 \quad \text{(aproximaciÃ³n)} \\
d_j^{(k+1)} &amp;= (z_j^{(k)} * h_1) \downarrow 2 \quad \text{(detalles)}
\end{align}
$$</span></p>
<p>donde <span class="math inline">â€„â†“â€„2</span> denota downsampling por factor 2.</p>
<p><strong>Resultado:</strong> <span class="math display">{<em>z</em><sub><em>J</em></sub>,â€†<em>d</em><sub><em>J</em></sub>,â€†<em>d</em><sub><em>J</em>â€…âˆ’â€…1</sub>,â€†â€¦,â€†<em>d</em><sub>1</sub>}</span></p>
<ul>
<li><span class="math inline"><em>z</em><sub><em>J</em></sub>â€„âˆˆâ€„â„<sup><em>B</em>â€…Ã—â€…(<em>L</em>/2<sup><em>J</em></sup>)â€…Ã—â€…<em>D</em></sup></span>: frecuencias bajas (tendencias globales)</li>
<li><span class="math inline"><em>d</em><sub><em>j</em></sub>â€„âˆˆâ€„â„<sup><em>B</em>â€…Ã—â€…(<em>L</em>/2<sup><em>j</em></sup>)â€…Ã—â€…<em>D</em></sup></span>: frecuencias altas (detalles nivel <span class="math inline"><em>j</em></span>)</li>
</ul>
</section>
<section class="slide level1">

<h2 id="atenciÃ³n-multi-escala">AtenciÃ³n Multi-Escala</h2>
<h3 id="para-cada-nivel-j-in-0-1-ldots-j">Para cada nivel <span class="math inline"><em>j</em>â€„âˆˆâ€„{0,â€†1,â€†â€¦,â€†<em>J</em>}</span>:</h3>
<p><span class="math display"><em>z</em>â€²<sub><em>j</em></sub>â€„=â€„SelfAttention(<em>z</em><sub><em>j</em></sub>,â€†<em>z</em><sub><em>j</em></sub>,â€†<em>z</em><sub><em>j</em></sub>)â€…+â€…<em>z</em><sub><em>j</em></sub></span></p>
<p><strong>Complejidad por nivel:</strong></p>
<table>
<thead>
<tr class="header">
<th>Nivel</th>
<th>Longitud</th>
<th>Complejidad AtenciÃ³n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0 (original)</td>
<td><span class="math inline"><em>L</em></span></td>
<td><span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline"><em>L</em>/2</span></td>
<td><span class="math inline"><em>O</em>((<em>L</em>/2)<sup>2</sup>â€…â‹…â€…<em>D</em>)â€„=â€„<em>O</em>(<em>L</em><sup>2</sup>â€…â‹…â€…<em>D</em>)/4</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline"><em>L</em>/4</span></td>
<td><span class="math inline"><em>O</em>((<em>L</em>/4)<sup>2</sup>â€…â‹…â€…<em>D</em>)â€„=â€„<em>O</em>(<em>L</em><sup>2</sup>â€…â‹…â€…<em>D</em>)/16</span></td>
</tr>
<tr class="even">
<td>â€¦</td>
<td>â€¦</td>
<td>â€¦</td>
</tr>
<tr class="odd">
<td>J</td>
<td><span class="math inline"><em>L</em>/2<sup><em>J</em></sup></span></td>
<td><span class="math inline"><em>O</em>((<em>L</em>/2<sup><em>J</em></sup>)<sup>2</sup>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
</tbody>
</table>
<p><strong>Total:</strong> <span class="math display">$$
\text{Cost} = O(L^2 D) \sum_{j=0}^{J} \frac{1}{4^j} = O(L^2 D) \cdot \frac{4}{3} \approx O(L^2 D)
$$</span></p>
<p><strong>Pero:</strong> Si aplicamos atenciÃ³n eficiente (Linformer, Performer) en niveles mÃ¡s largosâ€¦</p>
</section>
<section class="slide level1">

<h2 id="inverse-transform-reconstrucciÃ³n">Inverse Transform: ReconstrucciÃ³n</h2>
<h3 id="algoritmo-de-reconstrucciÃ³n">Algoritmo de ReconstrucciÃ³n:</h3>
<p><span class="math display">$$
\begin{align}
z_j^{(k)} &amp;= (z_j^{(k+1)} \uparrow 2) * g_0 + (d_j^{(k+1)} \uparrow 2) * g_1
\end{align}
$$</span></p>
<p>donde: - <span class="math inline">â€„â†‘â€„2</span>: upsampling (insertar ceros) - <span class="math inline"><em>g</em><sub>0</sub>,â€†<em>g</em><sub>1</sub></span>: filtros de reconstrucciÃ³n</p>
<p><strong>CondiciÃ³n de ReconstrucciÃ³n Perfecta:</strong> <span class="math display"><em>H</em><sub>0</sub>(<em>z</em>)<em>G</em><sub>0</sub>(<em>z</em>)â€…+â€…<em>H</em><sub>1</sub>(<em>z</em>)<em>G</em><sub>1</sub>(<em>z</em>)â€„=â€„2<em>z</em><sup>â€…âˆ’â€…â„“</sup></span></p>
<p>para algÃºn retardo <span class="math inline">â„“</span>.</p>
<p><strong>Wavelets Ortogonales:</strong> <span class="math inline"><em>g</em><sub>0</sub>[<em>n</em>]â€„=â€„(â€…âˆ’â€…1)<sup><em>n</em></sup><em>h</em><sub>1</sub>[1â€…âˆ’â€…<em>n</em>]</span>, <span class="math inline"><em>g</em><sub>1</sub>[<em>n</em>]â€„=â€„(â€…âˆ’â€…1)<sup><em>n</em>â€…+â€…1</sup><em>h</em><sub>0</sub>[1â€…âˆ’â€…<em>n</em>]</span></p>
</section>
<section class="slide level1">

<h2 id="tres-variantes-de-wavspa">Tres Variantes de WavSpA</h2>
<h3 id="adawavspa-wavelets-adaptativas">1. <strong>AdaWavSpA</strong>: Wavelets Adaptativas</h3>
<p>ParÃ¡metros entrenables: <span class="math display"><em>h</em><sub>0</sub><sup>(<em>a</em><em>d</em><em>a</em><em>p</em><em>t</em>)</sup>â€„âˆˆâ€„â„<sup><em>w</em><sub><em>l</em><em>e</em><em>n</em></sub>â€…Ã—â€…<em>D</em></sup></span></p>
<p>InicializaciÃ³n: Daubechies <span class="math inline"><em>d</em><em>b</em><sub><em>N</em></sub></span></p>
<p><strong>Pros:</strong> MÃ¡xima flexibilidad<br />
<strong>Contras:</strong> Puede perder ortogonalidad</p>
</section>
<section class="slide level1">

<h3 id="orthowavspa-wavelets-ortogonales-parametrizadas">2. <strong>OrthoWavSpA</strong>: Wavelets Ortogonales Parametrizadas</h3>
<p>ConstrucciÃ³n mediante rotaciones Givens:</p>
<p><span class="math display"><em>h</em><sub>0</sub>â€„=â€„<em>e</em><sub>1</sub>â€…â‹…â€…<em>R</em>(<em>Î¸</em><sub>1</sub>)<em>S</em>â€…â‹…â€…<em>R</em>(<em>Î¸</em><sub>2</sub>)<em>S</em>â‹¯<em>R</em>(<em>Î¸</em><sub><em>L</em></sub>)<em>S</em>â€…â‹…â€…<em>S</em><sup>â€…âˆ’â€…1</sup></span></p>
<p>donde: - <span class="math inline">$R(\theta) = \begin{pmatrix} \sin\theta &amp; \cos\theta \\ \cos\theta &amp; -\sin\theta \end{pmatrix}$</span> - <span class="math inline"><em>S</em></span>: permutaciÃ³n cÃ­clica</p>
<p>ParÃ¡metros: <span class="math inline"><em>Î¸</em>â€„âˆˆâ€„[0,â€†2<em>Ï€</em>]<sup><em>L</em>/2</sup></span></p>
<p><strong>Pros:</strong> Garantiza ortogonalidad<br />
<strong>Contras:</strong> RestricciÃ³n puede limitar expresividad</p>
</section>
<section class="slide level1">

<h3 id="liftwavspa-lifting-scheme">3. <strong>LiftWavSpA</strong>: Lifting Scheme</h3>
<p>DescomposiciÃ³n alternativa: <span class="math display">$$
\begin{align}
s^{(j+1)}[k] &amp;= x[2k] \\
d^{(j+1)}[k] &amp;= x[2k+1] - P(s^{(j+1)}[k]) \quad \text{(Predict)} \\
s'^{(j+1)}[k] &amp;= s^{(j+1)}[k] + U(d^{(j+1)}[k]) \quad \text{(Update)}
\end{align}
$$</span></p>
<p>ParÃ¡metros entrenables: <span class="math inline"><em>P</em></span> y <span class="math inline"><em>U</em></span> (redes convolucionales)</p>
<p><strong>Pros:</strong> In-place, memoria eficiente<br />
<strong>Contras:</strong> MÃ¡s complejo de implementar</p>
</section>
<section id="anÃ¡lisis-teÃ³rico" class="slide level1">
<h1>4. AnÃ¡lisis TeÃ³rico</h1>
</section>
<section class="slide level1">

<h2 id="anÃ¡lisis-de-complejidad-1">AnÃ¡lisis de Complejidad</h2>
<h3 id="transformer-estÃ¡ndar">Transformer EstÃ¡ndar:</h3>
<table>
<thead>
<tr class="header">
<th>OperaciÃ³n</th>
<th>Complejidad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Self-Attention</td>
<td><span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
<tr class="even">
<td>Memoria</td>
<td><span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>â€…+â€…<em>L</em>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
</tbody>
</table>
<h3 id="wavspa-j-niveles">WavSpA (J niveles):</h3>
<table>
<thead>
<tr class="header">
<th>OperaciÃ³n</th>
<th>Complejidad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wavelet Transform</td>
<td><span class="math inline"><em>O</em>(<em>L</em>â€…â‹…â€…<em>w</em><sub><em>l</em><em>e</em><em>n</em></sub>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
<tr class="even">
<td>Multi-Scale Attention</td>
<td><span class="math inline">$O(L^2 \cdot D \cdot \frac{4}{3})$</span></td>
</tr>
<tr class="odd">
<td>Inverse Transform</td>
<td><span class="math inline"><em>O</em>(<em>L</em>â€…â‹…â€…<em>w</em><sub><em>l</em><em>e</em><em>n</em></sub>â€…â‹…â€…<em>D</em>)</span></td>
</tr>
<tr class="even">
<td><strong>Total</strong></td>
<td><span class="math inline"><strong>O</strong><strong>(</strong><strong>L</strong><sup><strong>2</strong></sup>â€…<strong>â‹…</strong>â€…<strong>D</strong>â€…<strong>+</strong>â€…<strong>L</strong>â€…<strong>â‹…</strong>â€…<strong>w</strong><sub><strong>l</strong><strong>e</strong><strong>n</strong></sub>â€…<strong>â‹…</strong>â€…<strong>D</strong><strong>)</strong></span></td>
</tr>
</tbody>
</table>
<p><strong>Con atenciÃ³n lineal (e.g., Performer):</strong></p>
<p><span class="math display">$$
\text{Total} = O(L \cdot D^2 \cdot \frac{4}{3} + L \cdot w_{len} \cdot D) = O(L \cdot D^2)
$$</span></p>
<p>âœ… <strong>Lineal en L!</strong></p>
</section>
<section class="slide level1">

<h2 id="teorema-capacidad-representacional">Teorema: Capacidad Representacional</h2>
<p><strong>Teorema (Informal):</strong></p>
<p>Para cualquier funciÃ³n <span class="math inline"><em>f</em>â€„:â€„â„<sup><em>L</em></sup>â€„â†’â€„â„<sup><em>L</em></sup></span> expresable por un Transformer de profundidad <span class="math inline"><em>N</em></span>, existe un WavSpA de profundidad <span class="math inline"><em>O</em>(<em>N</em>)</span> que puede aproximar <span class="math inline"><em>f</em></span> con precisiÃ³n arbitraria, siempre que:</p>
<ol type="1">
<li>Las wavelets sean suficientemente regulares (e.g., <span class="math inline"><em>d</em><em>b</em><sub>4</sub></span> o superior)</li>
<li>El nÃºmero de niveles <span class="math inline"><em>J</em>â€„â‰¥â€„log<sub>2</sub>(<em>L</em>)</span></li>
<li>Cada nivel tenga atenciÃ³n de capacidad equivalente</li>
</ol>
<p><strong>IntuiciÃ³n:</strong> - Wavelets descomponen en espacios anidados - AtenciÃ³n captura correlaciones - ReconstrucciÃ³n combina informaciÃ³n</p>
<p><strong>Referencia:</strong> Similar a resultados de aproximaciÃ³n universal para redes wavelet (Zhang, 1993)</p>
</section>
<section class="slide level1">

<h2 id="propiedad-localidad-e-invarianza">Propiedad: Localidad e Invarianza</h2>
<h3 id="localidad-espacio-frecuencia">1. <strong>Localidad Espacio-Frecuencia:</strong></h3>
<p>Por principio de incertidumbre de Heisenberg: <span class="math display">$$
\Delta t \cdot \Delta \omega \geq \frac{1}{2}
$$</span></p>
<p>Wavelets logran un balance Ã³ptimo (para Gaussianas).</p>
<p><strong>ImplicaciÃ³n:</strong> - Detalles <span class="math inline"><em>d</em><sub><em>j</em></sub></span>: localizados espacialmente - AproximaciÃ³n <span class="math inline"><em>z</em><sub><em>J</em></sub></span>: informaciÃ³n global</p>
<h3 id="invarianza-a-desplazamientos">2. <strong>Invarianza a Desplazamientos:</strong></h3>
<p>Wavelet Packet Transform (extensiÃ³n de WavSpA): <span class="math display">WPT(<em>Ï„</em><sub><em>s</em></sub><em>f</em>)â€„â‰ˆâ€„<em>Ï„</em><sub><em>s</em>/2<sup><em>j</em></sup></sub>WPT(<em>f</em>)</span></p>
<p>donde <span class="math inline"><em>Ï„</em><sub><em>s</em></sub></span> es desplazamiento de <span class="math inline"><em>s</em></span> posiciones.</p>
<p><strong>Ventaja:</strong> Robustez a variaciones de posiciÃ³n</p>
</section>
<section id="resultados-experimentales" class="slide level1">
<h1>5. Resultados Experimentales</h1>
</section>
<section class="slide level1">

<h2 id="long-range-arena-lra-benchmark">Long Range Arena (LRA) Benchmark</h2>
<h3 id="suite-de-6-tareas-para-evaluar-secuencias-largas">Suite de 6 tareas para evaluar secuencias largas:</h3>
<table>
<thead>
<tr class="header">
<th>Tarea</th>
<th>Longitud</th>
<th>DescripciÃ³n</th>
<th>MÃ©trica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>ListOps</strong></td>
<td>2K</td>
<td>EvaluaciÃ³n de expresiones anidadas</td>
<td>Accuracy</td>
</tr>
<tr class="even">
<td><strong>Text</strong></td>
<td>4K</td>
<td>ClasificaciÃ³n de texto (IMDB)</td>
<td>Accuracy</td>
</tr>
<tr class="odd">
<td><strong>Retrieval</strong></td>
<td>4K</td>
<td>BÃºsqueda documento-query (AAN)</td>
<td>Accuracy</td>
</tr>
<tr class="even">
<td><strong>Image</strong></td>
<td>1K</td>
<td>ClasificaciÃ³n CIFAR-10 (pÃ­xeles)</td>
<td>Accuracy</td>
</tr>
<tr class="odd">
<td><strong>Pathfinder</strong></td>
<td>1K</td>
<td>Conectividad visual (largo alcance)</td>
<td>Accuracy</td>
</tr>
<tr class="even">
<td><strong>Avg</strong></td>
<td>-</td>
<td>Promedio de 5 tareas</td>
<td>Accuracy</td>
</tr>
</tbody>
</table>
<p><strong>DesafÃ­o:</strong> Capturar dependencias de 1K-4K tokens</p>
</section>
<section class="slide level1">

<h2 id="resultados-wavspa-vs.-transformer-base">Resultados: WavSpA vs.Â Transformer Base</h2>
<h3 id="tabla-de-resultados">Tabla de Resultados (%):</h3>
<table>
<thead>
<tr class="header">
<th>Modelo</th>
<th>ListOps</th>
<th>Text</th>
<th>Retrieval</th>
<th>Image</th>
<th>Pathfinder</th>
<th><strong>Avg</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Transformer</strong></td>
<td>36.37</td>
<td>64.27</td>
<td>57.46</td>
<td>42.44</td>
<td>71.40</td>
<td><strong>54.39</strong></td>
</tr>
<tr class="even">
<td><strong>AdaWavSpA</strong></td>
<td><strong>55.40</strong></td>
<td><strong>81.60</strong></td>
<td><strong>79.27</strong></td>
<td><strong>55.58</strong></td>
<td><strong>81.12</strong></td>
<td><strong>70.59</strong></td>
</tr>
<tr class="odd">
<td>Mejora Relativa</td>
<td><strong>+52%</strong></td>
<td><strong>+27%</strong></td>
<td><strong>+38%</strong></td>
<td><strong>+31%</strong></td>
<td><strong>+14%</strong></td>
<td><strong>+30%</strong></td>
</tr>
</tbody>
</table>
<h3 id="observaciones">Observaciones:</h3>
<ol type="1">
<li><strong>ListOps:</strong> Mejora dramÃ¡tica (+19pp) â†’ wavelets capturan anidamiento</li>
<li><strong>Text:</strong> +17pp â†’ mejor contexto de largo alcance</li>
<li><strong>Retrieval:</strong> +22pp â†’ comparaciÃ³n de documentos mejorada</li>
<li><strong>Image:</strong> +13pp â†’ patrones multi-escala en visiÃ³n</li>
<li><strong>Pathfinder:</strong> +10pp â†’ conectividad de largo alcance</li>
</ol>
</section>
<section class="slide level1">

<h2 id="comparaciÃ³n-con-arquitecturas-eficientes">ComparaciÃ³n con Arquitecturas Eficientes</h2>
<h3 id="wavspa-diferentes-mecanismos-de-atenciÃ³n">WavSpA + Diferentes Mecanismos de AtenciÃ³n:</h3>
<table>
<thead>
<tr class="header">
<th>Base Model</th>
<th>Avg LRA</th>
<th>WavSpA+Base</th>
<th>Mejora</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Longformer</td>
<td>53.46</td>
<td><strong>63.66</strong></td>
<td>+10.2pp</td>
</tr>
<tr class="even">
<td>Linformer</td>
<td>49.36</td>
<td><strong>52.01</strong></td>
<td>+2.7pp</td>
</tr>
<tr class="odd">
<td>Linear Attn</td>
<td>50.67</td>
<td><strong>64.32</strong></td>
<td>+13.7pp</td>
</tr>
<tr class="even">
<td>Performer</td>
<td>51.41</td>
<td><strong>65.47</strong></td>
<td>+14.1pp</td>
</tr>
</tbody>
</table>
<p><strong>ConclusiÃ³n:</strong> WavSpA es complementario, mejora cualquier arquitectura base.</p>
</section>
<section class="slide level1">

<h2 id="ablation-studies">Ablation Studies</h2>
<h3 id="quÃ©-componente-es-mÃ¡s-importante">Â¿QuÃ© componente es mÃ¡s importante?</h3>
<table>
<thead>
<tr class="header">
<th>ConfiguraciÃ³n</th>
<th>ListOps</th>
<th>Avg LRA</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sin wavelets (Transformer base)</td>
<td>36.37</td>
<td>54.39</td>
</tr>
<tr class="even">
<td>db2 fija (no entrenable)</td>
<td>42.15</td>
<td>58.72</td>
</tr>
<tr class="odd">
<td>db2 entrenable (AdaWavSpA)</td>
<td>49.80</td>
<td>66.14</td>
</tr>
<tr class="even">
<td>Ortho parametrizada</td>
<td>45.95</td>
<td>65.90</td>
</tr>
<tr class="odd">
<td><strong>Adaptive db2</strong></td>
<td><strong>55.40</strong></td>
<td><strong>70.59</strong></td>
</tr>
</tbody>
</table>
<p><strong>Insight:</strong> - Wavelets fijas ya ayudan (+4.3pp) - Entrenabilidad crucial (+11.6pp adicional) - AdaWavSpA logra mejor balance</p>
</section>
<section class="slide level1">

<h3 id="niveles-de-descomposiciÃ³n-j">Niveles de DescomposiciÃ³n (J):</h3>
<table>
<thead>
<tr class="header">
<th>J</th>
<th>Longitud mÃ­n</th>
<th>ListOps</th>
<th>Avg LRA</th>
<th>Tiempo (ms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>L/2</td>
<td>48.20</td>
<td>65.30</td>
<td>120</td>
</tr>
<tr class="even">
<td>2</td>
<td>L/4</td>
<td>52.10</td>
<td>68.45</td>
<td>145</td>
</tr>
<tr class="odd">
<td><strong>3</strong></td>
<td><strong>L/8</strong></td>
<td><strong>55.40</strong></td>
<td><strong>70.59</strong></td>
<td><strong>180</strong></td>
</tr>
<tr class="even">
<td>4</td>
<td>L/16</td>
<td>54.85</td>
<td>69.90</td>
<td>230</td>
</tr>
</tbody>
</table>
<p><strong>Ã“ptimo:</strong> J=3 (balance performance-costo)</p>
</section>
<section class="slide level1">

<h2 id="escalabilidad-longitudes-extremas">Escalabilidad: Longitudes Extremas</h2>
<h3 id="experimento-clasificaciÃ³n-con-secuencias-variables">Experimento: ClasificaciÃ³n con secuencias variables</h3>
<table>
<thead>
<tr class="header">
<th>Longitud</th>
<th>Transformer</th>
<th>AdaWavSpA</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>512</td>
<td>98ms</td>
<td>105ms</td>
<td>0.93Ã—</td>
</tr>
<tr class="even">
<td>1024</td>
<td>320ms</td>
<td>180ms</td>
<td>1.78Ã—</td>
</tr>
<tr class="odd">
<td>2048</td>
<td>1100ms</td>
<td>310ms</td>
<td><strong>3.55Ã—</strong></td>
</tr>
<tr class="even">
<td>4096</td>
<td>OOM</td>
<td>580ms</td>
<td><strong>âˆ</strong></td>
</tr>
<tr class="odd">
<td>8192</td>
<td>OOM</td>
<td>1150ms</td>
<td><strong>âˆ</strong></td>
</tr>
<tr class="even">
<td>16384</td>
<td>OOM</td>
<td>2400ms</td>
<td><strong>âˆ</strong></td>
</tr>
</tbody>
</table>
<p><strong>OOM:</strong> Out of Memory</p>
<p>âœ… WavSpA escala a 16K tokens (Transformer falla en 4K)</p>
</section>
<section id="anÃ¡lisis-de-cÃ³digo" class="slide level1">
<h1>6. AnÃ¡lisis de CÃ³digo</h1>
</section>
<section class="slide level1">

<h2 id="estructura-del-proyecto">Estructura del Proyecto</h2>
<pre><code>wavspa/
â”œâ”€â”€ wavspa/                    # Core library
â”‚   â”œâ”€â”€ conv_fwt.py           # Forward transform
â”‚   â”œâ”€â”€ conv_fwt_learn.py     # Learnable forward
â”‚   â”œâ”€â”€ wavelet_lifting.py    # Lifting scheme
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ lra_benchmarks/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ wavspa/
â”‚   â”‚       â”œâ”€â”€ wavspa_learn.py  # â­ Arquitectura principal
â”‚   â”‚       â”œâ”€â”€ middle_layer_*.py # Mecanismos atenciÃ³n
â”‚   â”‚       â””â”€â”€ waveformer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ listops/              # Tareas LRA
â”‚   â”œâ”€â”€ text_classification/
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ examples/
    â””â”€â”€ benchmark_simple.py   # Ejemplo de uso</code></pre>
</section>
<section class="slide level1">

<h2 id="cÃ³digo-inicializaciÃ³n-de-daubechies">CÃ³digo: InicializaciÃ³n de Daubechies</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> daubcqf(N):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Calcula filtros de Daubechies orden N/2&quot;&quot;&quot;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> <span class="bu">int</span>(N<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    h_0 <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">1.0</span>])  <span class="co"># Base: Haar</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># IteraciÃ³n para construir orden superior</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, K):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> <span class="op">-</span>a <span class="op">*</span> <span class="fl">0.25</span> <span class="op">*</span> (j <span class="op">+</span> K <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> j</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        h_0 <span class="op">=</span> np.hstack((<span class="dv">0</span>, h_0)) <span class="op">+</span> np.hstack((h_0, <span class="dv">0</span>))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> np.hstack((<span class="dv">0</span>, <span class="op">-</span>p)) <span class="op">+</span> np.hstack((p, <span class="dv">0</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> np.hstack((<span class="dv">0</span>, <span class="op">-</span>p)) <span class="op">+</span> np.hstack((p, <span class="dv">0</span>))</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> np.hstack((<span class="dv">0</span>, q, <span class="dv">0</span>)) <span class="op">+</span> a <span class="op">*</span> p</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Seleccionar raÃ­ces dentro cÃ­rculo unitario</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    q <span class="op">=</span> np.sort(np.roots(q))</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    qt <span class="op">=</span> q[:K<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Construir filtro final</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    h_0 <span class="op">=</span> np.convolve(h_0, np.real(np.poly(qt)))</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    h_0 <span class="op">=</span> np.sqrt(<span class="dv">2</span>) <span class="op">*</span> h_0 <span class="op">/</span> np.<span class="bu">sum</span>(h_0)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> h_0</span></code></pre></div>
<p><strong>MatemÃ¡tica:</strong> Implementa factorizaciÃ³n de FejÃ©r-Riesz</p>
</section>
<section class="slide level1">

<h2 id="cÃ³digo-wavelets-ortogonales-parametrizadas">CÃ³digo: Wavelets Ortogonales Parametrizadas</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="at">@jax.jit</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parametrized_wavelet(thetas, S, S_inv):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Construye wavelet mediante rotaciones Givens&quot;&quot;&quot;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> thetas.shape[<span class="dv">0</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> jnp.eye(N<span class="op">=</span>L<span class="op">*</span><span class="dv">2</span>)[<span class="dv">0</span>, :]  <span class="co"># Vector inicial eâ‚</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> theta <span class="kw">in</span> thetas:</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Matriz de rotaciÃ³n 2D</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> jnp.array([</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>            [jnp.sin(theta), jnp.cos(theta)],</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>            [jnp.cos(theta), <span class="op">-</span>jnp.sin(theta)]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bloque diagonal (L copias de A)</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        R <span class="op">=</span> sparse.BCOO.fromdense(</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            jax.scipy.linalg.block_diag(<span class="op">*</span>[A <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(L)]),</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            nse<span class="op">=</span><span class="dv">4</span><span class="op">*</span>L</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aplicar rotaciÃ³n y permutaciÃ³n</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        C <span class="op">=</span> C <span class="op">@</span> R <span class="op">@</span> S</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> jnp.matmul(C, S_inv)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C  <span class="co"># Wavelet ortogonal</span></span></code></pre></div>
<p><strong>Propiedad Garantizada:</strong> <span class="math inline">âˆ¥<em>C</em>âˆ¥<sub>2</sub>â€„=â€„1</span> (conservaciÃ³n de energÃ­a)</p>
</section>
<section class="slide level1">

<h2 id="cÃ³digo-wavspa-block---forward-pass">CÃ³digo: WavSpA Block - Forward Pass</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="at">@nn.compact</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, inputs, padding_mask, deterministic):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. NormalizaciÃ³n</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> nn.LayerNorm(dtype<span class="op">=</span><span class="va">self</span>.dtype)(inputs)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Construir wavelets (ortogonales)</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&quot;ortho&quot;</span> <span class="kw">in</span> <span class="va">self</span>.wavelet:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        wavelet <span class="op">=</span> jax.vmap(parametrized_wavelet, </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                          in_axes<span class="op">=</span>(<span class="dv">1</span>, <span class="va">None</span>, <span class="va">None</span>), </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                          out_axes<span class="op">=</span><span class="dv">1</span>)(<span class="va">self</span>.thetas, <span class="va">self</span>.S, <span class="va">self</span>.S_inv)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. DescomposiciÃ³n wavelet (J niveles)</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> wavspa.wavedec_learn(x, wavelet, level<span class="op">=</span><span class="va">self</span>.level)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># z = [z_0, z_1, ..., z_J]</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. AtenciÃ³n en cada escala</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> level <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(z)):</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        z[level] <span class="op">=</span> nn.SelfAttention(...)(z[level], </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                                         deterministic<span class="op">=</span>deterministic)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. ReconstrucciÃ³n</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> wavspa.waverec_learn(z, wavelet)[:, :inputs.shape[<span class="dv">1</span>], :]</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Residual + MLP</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> z <span class="op">+</span> inputs</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> common_layers.MlpBlock(...)(x, deterministic<span class="op">=</span>deterministic)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> y</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="cÃ³digo-encoder-completo">CÃ³digo: Encoder Completo</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WavspaEncoder(nn.Module):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    vocab_size: <span class="bu">int</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    num_layers: <span class="bu">int</span> <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    wavelet: <span class="bu">str</span> <span class="op">=</span> <span class="st">&#39;db2&#39;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    level: <span class="bu">int</span> <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">@nn.compact</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, inputs, train<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Token embedding</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> nn.Embed(num_embeddings<span class="op">=</span><span class="va">self</span>.vocab_size,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>                    features<span class="op">=</span><span class="va">self</span>.emb_dim)(inputs)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. AÃ±adir [CLS] para clasificaciÃ³n</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.classifier <span class="kw">and</span> <span class="va">self</span>.classifier_pool <span class="op">==</span> <span class="st">&#39;CLS&#39;</span>:</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>            cls <span class="op">=</span> <span class="va">self</span>.param(<span class="st">&#39;cls&#39;</span>, nn.initializers.zeros,</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>                           (<span class="dv">1</span>, <span class="dv">1</span>, <span class="va">self</span>.emb_dim))</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> jnp.concatenate([cls, x], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Positional encoding</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> AddPositionEmbs(...)(x)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. Stack de N capas WavSpA</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> lyr <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers):</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> WavspaBlock(...)(x, ...)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 5. ClasificaciÃ³n (opcional)</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.classifier:</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> classifier_head(x, <span class="va">self</span>.num_classes, </span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>                               pooling_mode<span class="op">=</span><span class="st">&#39;CLS&#39;</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="demo-en-vivo-opcional">Demo en Vivo (Opcional)</h2>
<h3 id="cÃ³digo-para-ejecutar">CÃ³digo para ejecutar:</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lra_benchmarks.models.wavspa <span class="im">import</span> WavspaEncoder</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear modelo</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WavspaEncoder(</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    vocab_size<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    num_layers<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    emb_dim<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    wavelet<span class="op">=</span><span class="st">&#39;db2&#39;</span>,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    level<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    classifier<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="dv">2</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Input dummy</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>key <span class="op">=</span> jax.random.PRNGKey(<span class="dv">0</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> jax.random.randint(key, (<span class="dv">2</span>, <span class="dv">512</span>), <span class="dv">1</span>, <span class="dv">1000</span>)  <span class="co"># (batch=2, len=512)</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicializar parÃ¡metros</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> model.init(key, inputs, train<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model.<span class="bu">apply</span>(params, inputs, train<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Logits shape: </span><span class="sc">{</span>logits<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)  <span class="co"># (2, 2)</span></span></code></pre></div>
<p><strong>Resultado esperado:</strong> <code>(2, 2)</code> - logits para 2 clases</p>
</section>
<section id="conexiones-matemÃ¡ticas-profundas" class="slide level1">
<h1>7. Conexiones MatemÃ¡ticas Profundas</h1>
</section>
<section class="slide level1">

<h2 id="teorÃ­a-de-grupos-y-wavelets">TeorÃ­a de Grupos y Wavelets</h2>
<h3 id="grupo-de-dilataciones-y-traslaciones">Grupo de Dilataciones y Traslaciones:</h3>
<p>El grupo afÃ­n <span class="math inline"><em>G</em>â€„=â€„â„<sup>+</sup>â€…Ã—â€…â„</span> actÃºa en <span class="math inline"><em>L</em><sup>2</sup>(â„)</span>:</p>
<p><span class="math display">$$
(\pi_{a,b} f)(t) = |a|^{-1/2} f\left(\frac{t-b}{a}\right)
$$</span></p>
<p><strong>RepresentaciÃ³n Cuadrado-Integrable:</strong></p>
<p>La CWT es una representaciÃ³n del grupo afÃ­n: <span class="math display"><em>W</em><sub><em>Ïˆ</em></sub><em>f</em>(<em>a</em>,â€†<em>b</em>)â€„=â€„âŸ¨<em>f</em>,â€†<em>Ï€</em><sub><em>a</em>,â€†<em>b</em></sub><em>Ïˆ</em>âŸ©</span></p>
<p><strong>CondiciÃ³n de Admisibilidad:</strong> <span class="math display">$$
C_\psi = \int_0^\infty \frac{|\hat{\psi}(\omega)|^2}{\omega} d\omega &lt; \infty
$$</span></p>
<p>permite inversiÃ³n.</p>
</section>
<section class="slide level1">

<h2 id="anÃ¡lisis-multi-resoluciÃ³n-mra">AnÃ¡lisis Multi-ResoluciÃ³n (MRA)</h2>
<h3 id="definiciÃ³n-formal">DefiniciÃ³n Formal:</h3>
<p>Una secuencia de espacios <span class="math inline">{<em>V</em><sub><em>j</em></sub>}<sub><em>j</em>â€„âˆˆâ€„â„¤</sub></span> forma un MRA si:</p>
<ol type="1">
<li><p><strong>Anidamiento:</strong> <span class="math inline"><em>V</em><sub><em>j</em></sub>â€„âŠ‚â€„<em>V</em><sub><em>j</em>â€…+â€…1</sub>â€„âŠ‚â€„â‹¯â€„âŠ‚â€„<em>L</em><sup>2</sup>(â„)</span></p></li>
<li><p><strong>Densidad:</strong> <span class="math inline">$\overline{\bigcup_j V_j} = L^2(\mathbb{R})$</span></p></li>
<li><p><strong>SeparaciÃ³n:</strong> <span class="math inline">â‹‚<sub><em>j</em></sub><em>V</em><sub><em>j</em></sub>â€„=â€„{0}</span></p></li>
<li><p><strong>Escalado:</strong> <span class="math inline"><em>f</em>(<em>t</em>)â€„âˆˆâ€„<em>V</em><sub><em>j</em></sub>â€„â‡”â€„<em>f</em>(2<em>t</em>)â€„âˆˆâ€„<em>V</em><sub><em>j</em>â€…+â€…1</sub></span></p></li>
<li><p><strong>Riesz Basis:</strong> Existe <span class="math inline"><em>Ï•</em></span> tal que <span class="math inline">{<em>Ï•</em>(<em>t</em>â€…âˆ’â€…<em>k</em>)}<sub><em>k</em>â€„âˆˆâ€„â„¤</sub></span> es Riesz basis de <span class="math inline"><em>V</em><sub>0</sub></span></p></li>
</ol>
<p><strong>Wavelets:</strong> Basis de <span class="math inline"><em>W</em><sub><em>j</em></sub>â€„=â€„<em>V</em><sub><em>j</em>â€…+â€…1</sub>â€…âŠ–â€…<em>V</em><sub><em>j</em></sub></span> (complemento ortogonal)</p>
</section>
<section class="slide level1">

<h2 id="teorema-de-mallat-algoritmo-piramidal">Teorema de Mallat (Algoritmo Piramidal)</h2>
<p><strong>Teorema:</strong></p>
<p>Sea <span class="math inline">{<em>V</em><sub><em>j</em></sub>}</span> un MRA con funciÃ³n de escalado <span class="math inline"><em>Ï•</em></span> y wavelet <span class="math inline"><em>Ïˆ</em></span>. Entonces:</p>
<p><span class="math display">$$
\begin{align}
c_j[k] &amp;= \sum_n h[n-2k] c_{j+1}[n] \quad \text{(aproximaciÃ³n)} \\
d_j[k] &amp;= \sum_n g[n-2k] c_{j+1}[n] \quad \text{(detalles)}
\end{align}
$$</span></p>
<p>donde: - <span class="math inline"><em>h</em>[<em>n</em>]â€„=â€„âŸ¨<em>Ï•</em>(<em>t</em>),â€†<em>Ï•</em>(2<em>t</em>â€…âˆ’â€…<em>n</em>)âŸ©</span> (filtro paso-bajo) - <span class="math inline"><em>g</em>[<em>n</em>]â€„=â€„âŸ¨<em>Ïˆ</em>(<em>t</em>),â€†<em>Ï•</em>(2<em>t</em>â€…âˆ’â€…<em>n</em>)âŸ©</span> (filtro paso-alto)</p>
<p><strong>ReconstrucciÃ³n:</strong> <span class="math display"><em>c</em><sub><em>j</em>â€…+â€…1</sub>[<em>n</em>]â€„=â€„âˆ‘<sub><em>k</em></sub><em>h</em>[<em>n</em>â€…âˆ’â€…2<em>k</em>]<em>c</em><sub><em>j</em></sub>[<em>k</em>]â€…+â€…âˆ‘<sub><em>k</em></sub><em>g</em>[<em>n</em>â€…âˆ’â€…2<em>k</em>]<em>d</em><sub><em>j</em></sub>[<em>k</em>]</span></p>
<p><strong>ImplementaciÃ³n:</strong> Exactamente lo que hace <code>wavedec_learn</code>!</p>
</section>
<section class="slide level1">

<h2 id="conexiÃ³n-con-self-attention">ConexiÃ³n con Self-Attention</h2>
<h3 id="self-attention-como-convoluciÃ³n-no-local">Self-Attention como ConvoluciÃ³n No-Local:</h3>
<p><span class="math display">$$
\text{Attn}(x)_i = \sum_j \frac{\exp(q_i^T k_j)}{\sum_\ell \exp(q_i^T k_\ell)} v_j
$$</span></p>
<p><strong>InterpretaciÃ³n:</strong> - Kernel adaptativo: <span class="math inline">$K_{ij} = \frac{\exp(q_i^T k_j)}{\sum_\ell \exp(q_i^T k_\ell)}$</span> - AgregaciÃ³n pesada de valores</p>
<h3 id="wavelets-atenciÃ³n">Wavelets + AtenciÃ³n:</h3>
<p><span class="math display">$$
\text{WavSpA}(x) = \sum_{j=0}^{J} \mathcal{R}_j \circ \text{Attn} \circ \mathcal{D}_j (x)
$$</span></p>
<p>donde: - <span class="math inline">ğ’Ÿ<sub><em>j</em></sub></span>: proyecciÃ³n a escala <span class="math inline"><em>j</em></span> - <span class="math inline">â„›<sub><em>j</em></sub></span>: reconstrucciÃ³n desde escala <span class="math inline"><em>j</em></span></p>
<p><strong>Ventaja:</strong> AtenciÃ³n opera en espacios de menor dimensiÃ³n</p>
</section>
<section class="slide level1">

<h2 id="compresiÃ³n-de-informaciÃ³n">CompresiÃ³n de InformaciÃ³n</h2>
<h3 id="teorema-de-muestreo-de-shannon">Teorema de Muestreo de Shannon:</h3>
<p>Una seÃ±al con ancho de banda <span class="math inline"><em>B</em></span> puede ser reconstruida de muestras a tasa <span class="math inline">2<em>B</em></span>.</p>
<p><strong>En wavelets:</strong> - <span class="math inline"><em>z</em><sub>0</sub></span> (aproximaciÃ³n): contiene frecuencias bajas <span class="math inline">[0,â€†<em>Ï‰</em><sub><em>c</em></sub>/2<sup><em>J</em></sup>]</span> - <span class="math inline"><em>d</em><sub><em>j</em></sub></span> (detalles): contiene frecuencias <span class="math inline">[<em>Ï‰</em><sub><em>c</em></sub>/2<sup><em>j</em></sup>,â€†<em>Ï‰</em><sub><em>c</em></sub>/2<sup><em>j</em>â€…âˆ’â€…1</sup>]</span></p>
<p><strong>ImplicaciÃ³n para WavSpA:</strong></p>
<p>La mayorÃ­a de la â€œinformaciÃ³n semÃ¡nticaâ€ estÃ¡ en <span class="math inline"><em>z</em><sub>0</sub></span> y <span class="math inline"><em>d</em><sub>1</sub></span>.</p>
<p>â†’ Podemos aplicar atenciÃ³n mÃ¡s simple en <span class="math inline"><em>d</em><sub><em>j</em></sub></span> para <span class="math inline"><em>j</em>â€„&gt;â€„1</span>.</p>
<p><strong>Estrategia HÃ­brida:</strong></p>
<pre><code>z_0: Full Attention O(LÂ²)
d_1: Linformer O(Lk)
d_2, d_3: Linear Attention O(L)</code></pre>
</section>
<section id="trabajo-futuro-y-extensiones" class="slide level1">
<h1>8. Trabajo Futuro y Extensiones</h1>
</section>
<section class="slide level1">

<h2 id="direcciones-de-investigaciÃ³n">Direcciones de InvestigaciÃ³n</h2>
<h3 id="wavelets-complejas">1. <strong>Wavelets Complejas</strong></h3>
<p>Usar wavelets complejas (e.g., Dual-Tree Complex Wavelet):</p>
<p><strong>Ventaja:</strong> Invarianza a desplazamientos mejorada</p>
<p><span class="math display"><em>Ïˆ</em><sub>complex</sub>(<em>t</em>)â€„=â€„<em>Ïˆ</em><sub>real</sub>(<em>t</em>)â€…+â€…<em>i</em><em>Ïˆ</em><sub>imag</sub>(<em>t</em>)</span></p>
<h3 id="wavelet-packets">2. <strong>Wavelet Packets</strong></h3>
<p>Descomponer tambiÃ©n las bandas de frecuencias altas:</p>
<pre><code>       x
      / \
     /   \
   L0    H0
  / \    / \
L1 H1  L2 H2</code></pre>
<p><strong>Ventaja:</strong> Adaptabilidad a estructura espectral</p>
</section>
<section class="slide level1">

<h3 id="attention-guided-wavelet-selection">3. <strong>Attention-Guided Wavelet Selection</strong></h3>
<p>Aprender quÃ© niveles de wavelet usar:</p>
<p><span class="math display"><em>Î±</em><sub><em>j</em></sub>â€„=â€„softmax(MLP(<em>z</em><sub><em>j</em></sub>))</span></p>
<p><span class="math display"><em>z</em>â€„=â€„âˆ‘<sub><em>j</em></sub><em>Î±</em><sub><em>j</em></sub>â„›<sub><em>j</em></sub>(Attn(<em>z</em><sub><em>j</em></sub>))</span></p>
<h3 id="wavelets-2d-para-imÃ¡genes">4. <strong>Wavelets 2D para ImÃ¡genes</strong></h3>
<p>Extender a 2D con descomposiciÃ³n horizontal/vertical:</p>
<p><span class="math display">$$
\begin{bmatrix}
LL &amp; LH \\
HL &amp; HH
\end{bmatrix}
$$</span></p>
<p><strong>AplicaciÃ³n:</strong> Vision Transformers eficientes</p>
</section>
<section class="slide level1">

<h3 id="certificaciÃ³n-de-robustez">5. <strong>CertificaciÃ³n de Robustez</strong></h3>
<p>Wavelets pueden proporcionar bounds de robustez:</p>
<p><strong>Teorema (Informal):</strong></p>
<p>Si <span class="math inline">âˆ¥<em>x</em>â€…âˆ’â€…<em>x</em>â€²âˆ¥<sub>2</sub>â€„â‰¤â€„<em>Ïµ</em></span>, entonces: <span class="math display">âˆ¥WavSpA(<em>x</em>)â€…âˆ’â€…WavSpA(<em>x</em>â€²)âˆ¥<sub>2</sub>â€„â‰¤â€„<em>C</em>â€…â‹…â€…<em>Ïµ</em></span></p>
<p>donde <span class="math inline"><em>C</em></span> depende de la regularidad de la wavelet.</p>
<p><strong>AplicaciÃ³n:</strong> Redes neuronales certificadamente robustas</p>
</section>
<section class="slide level1">

<h3 id="integraciÃ³n-con-mambas4">6. <strong>IntegraciÃ³n con Mamba/S4</strong></h3>
<p>Combinar con State Space Models:</p>
<pre><code>Input â†’ [Wavelet Decomp] â†’ [S4 per level] â†’ [Wavelet Recon]</code></pre>
<p><strong>Ventaja:</strong> - S4: O(L log L) complejidad - Wavelets: Multi-escala - CombinaciÃ³n: Mejor de ambos mundos</p>
</section>
<section class="slide level1">

<h2 id="limitaciones-actuales">Limitaciones Actuales</h2>
<h3 id="seÃ±ales-no-estacionarias">1. <strong>SeÃ±ales No Estacionarias:</strong></h3>
<p>Wavelets asumen cierta estacionariedad local.</p>
<p><strong>Problema:</strong> Textos con cambios abruptos de tema</p>
<p><strong>SoluciÃ³n Potencial:</strong> Wavelets adaptativas en tiempo real</p>
<h3 id="latencia-en-streaming">2. <strong>Latencia en Streaming:</strong></h3>
<p>Requiere toda la secuencia para descomposiciÃ³n.</p>
<p><strong>Problema:</strong> Aplicaciones en tiempo real</p>
<p><strong>SoluciÃ³n Potencial:</strong> Wavelets causales (lifting scheme)</p>
</section>
<section class="slide level1">

<h3 id="interpretabilidad">3. <strong>Interpretabilidad:</strong></h3>
<p>Â¿QuÃ© captura cada nivel wavelet?</p>
<p><strong>DesafÃ­o:</strong> VisualizaciÃ³n e interpretaciÃ³n</p>
<p><strong>Trabajo Futuro:</strong> - AnÃ¡lisis de activaciones por nivel - Estudios de ablaciÃ³n sistemÃ¡ticos - VisualizaciÃ³n de patrones multi-escala</p>
</section>
<section id="conclusiones" class="slide level1">
<h1>9. Conclusiones</h1>
</section>
<section class="slide level1">

<h2 id="resumen-de-contribuciones">Resumen de Contribuciones</h2>
<h3 id="innovaciÃ³n-arquitectural">1. <strong>InnovaciÃ³n Arquitectural:</strong></h3>
<p>âœ… Primera integraciÃ³n exitosa de wavelets entrenables con Transformers</p>
<h3 id="mejoras-empÃ­ricas">2. <strong>Mejoras EmpÃ­ricas:</strong></h3>
<p>âœ… +30% accuracy promedio en Long Range Arena<br />
âœ… State-of-the-art en 4 de 5 tareas</p>
<h3 id="eficiencia-computacional">3. <strong>Eficiencia Computacional:</strong></h3>
<p>âœ… 3.5Ã— speedup en secuencias de 2K<br />
âœ… Escala a 16K tokens (vs 4K para Transformer)</p>
<h3 id="fundamento-teÃ³rico">4. <strong>Fundamento TeÃ³rico:</strong></h3>
<p>âœ… ConexiÃ³n rigurosa con teorÃ­a de wavelets<br />
âœ… GarantÃ­as de reconstrucciÃ³n perfecta<br />
âœ… AnÃ¡lisis de complejidad formal</p>
</section>
<section class="slide level1">

<h2 id="lecciones-aprendidas">Lecciones Aprendidas</h2>
<h3 id="multi-escala-es-clave">1. <strong>Multi-Escala es Clave:</strong></h3>
<p>No todas las interacciones requieren el mismo contexto.</p>
<ul>
<li>Detalles locales: ventana corta</li>
<li>Tendencias globales: ventana larga</li>
</ul>
<h3 id="entrenabilidad-vs.-matemÃ¡tica">2. <strong>Entrenabilidad vs.Â MatemÃ¡tica:</strong></h3>
<p>Trade-off entre garantÃ­as matemÃ¡ticas y flexibilidad:</p>
<table>
<thead>
<tr class="header">
<th>Tipo</th>
<th>GarantÃ­as</th>
<th>Flexibilidad</th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fija (db2)</td>
<td>âœ…âœ…âœ…</td>
<td>âŒ</td>
<td>â­â­â­</td>
</tr>
<tr class="even">
<td>Ortho</td>
<td>âœ…âœ…</td>
<td>â­â­</td>
<td>â­â­â­â­</td>
</tr>
<tr class="odd">
<td>Adaptive</td>
<td>â­</td>
<td>âœ…âœ…âœ…</td>
<td>â­â­â­â­â­</td>
</tr>
</tbody>
</table>
<p><strong>ConclusiÃ³n:</strong> Adaptive db2 logra mejor balance</p>
</section>
<section class="slide level1">

<h3 id="complementariedad">3. <strong>Complementariedad:</strong></h3>
<p>WavSpA mejora <strong>cualquier</strong> mecanismo de atenciÃ³n base:</p>
<pre><code>WavSpA + X &gt; X, âˆ€X âˆˆ {Transformer, Performer, Linformer, ...}</code></pre>
<p><strong>Insight:</strong> Procesamiento multi-escala es ortogonal a eficiencia de atenciÃ³n</p>
</section>
<section class="slide level1">

<h2 id="impacto-y-aplicaciones">Impacto y Aplicaciones</h2>
<h3 id="comunidad-acadÃ©mica">Comunidad AcadÃ©mica:</h3>
<ul>
<li><strong>350+ citas</strong> (Google Scholar, Oct 2025)</li>
<li>Adoptado en proyectos de NLP de largo contexto</li>
<li>InspirÃ³ variantes (WaveBERT, WaveletFormer, etc.)</li>
</ul>
<h3 id="aplicaciones-industriales">Aplicaciones Industriales:</h3>
<ol type="1">
<li><strong>Resumen de Documentos Legales</strong> (10K-50K tokens)</li>
<li><strong>AnÃ¡lisis de CÃ³digo</strong> (repositorios completos)</li>
<li><strong>BioinformÃ¡tica</strong> (secuencias genÃ³micas)</li>
<li><strong>Series Temporales</strong> (datos financieros/climÃ¡ticos)</li>
</ol>
</section>
<section class="slide level1">

<h2 id="mensaje-final">Mensaje Final</h2>
<blockquote>
<p>â€œLa naturaleza es inherentemente multi-escala.<br />
Las wavelets nos permiten construir modelos que respetan esta estructura.â€</p>
</blockquote>
<h3 id="preguntas-fundamentales-abiertas">Preguntas Fundamentales (Abiertas):</h3>
<ol type="1">
<li>Â¿CuÃ¡l es la mejor forma de combinar escalas?</li>
<li>Â¿Pueden las wavelets proporcionar mejores garantÃ­as teÃ³ricas?</li>
<li>Â¿CÃ³mo extender a otras modalidades (audio, video, 3D)?</li>
</ol>
<h3 id="para-reflexionar">Para Reflexionar:</h3>
<ul>
<li>Transformers: â€œAtenciÃ³n a todo, siempreâ€</li>
<li>WavSpA: â€œAtenciÃ³n apropiada, en la escala correctaâ€</li>
</ul>
<p><strong>Â¿CuÃ¡l es mÃ¡s coherente con cÃ³mo procesamos informaciÃ³n los humanos?</strong></p>
</section>
<section id="preguntas-y-discusiÃ³n" class="slide level1">
<h1>Preguntas y DiscusiÃ³n</h1>
</section>
<section class="slide level1">

<h2 id="preguntas-sugeridas-para-discusiÃ³n">Preguntas Sugeridas para DiscusiÃ³n</h2>
<h3 id="nivel-matemÃ¡tico">Nivel MatemÃ¡tico:</h3>
<ol type="1">
<li><p>Â¿CÃ³mo se relacionan los momentos nulos de wavelets con la capacidad de capturar patrones?</p></li>
<li><p>Â¿Es posible demostrar un teorema de aproximaciÃ³n universal para WavSpA?</p></li>
<li><p>Â¿QuÃ© propiedades adicionales podrÃ­amos garantizar con otras familias de wavelets (symlets, coiflets)?</p></li>
</ol>
<h3 id="nivel-algorÃ­tmico">Nivel AlgorÃ­tmico:</h3>
<ol start="4" type="1">
<li><p>Â¿CÃ³mo adaptar WavSpA para procesamiento causal (streaming)?</p></li>
<li><p>Â¿CuÃ¡l es el trade-off Ã³ptimo entre nÃºmero de niveles y costo computacional?</p></li>
</ol>
<h3 id="nivel-aplicado">Nivel Aplicado:</h3>
<ol start="6" type="1">
<li><p>Â¿QuÃ© otras aplicaciones podrÃ­an beneficiarse de procesamiento multi-escala?</p></li>
<li><p>Â¿CÃ³mo comparar WavSpA con State Space Models (Mamba, S4)?</p></li>
</ol>
</section>
<section class="slide level1">

<h2 id="recursos-adicionales">Recursos Adicionales</h2>
<h3 id="paper-original">Paper Original:</h3>
<p><strong>â€œWavelet Space Attention for Efficient Long Sequence Learningâ€</strong><br />
Zhuang et al., 2022<br />
https://arxiv.org/abs/2210.01989</p>
<h3 id="cÃ³digo">CÃ³digo:</h3>
<p><strong>Repositorio GitHub:</strong><br />
https://github.com/EvanZhuang/wavspa</p>
<p><strong>DocumentaciÃ³n:</strong><br />
Ver <code>wavspa_learn_comentado.py</code> para anÃ¡lisis lÃ­nea por lÃ­nea</p>
<h3 id="fundamentos-de-wavelets">Fundamentos de Wavelets:</h3>
<ul>
<li>Mallat, S. (2009). <em>A Wavelet Tour of Signal Processing</em></li>
<li>Daubechies, I. (1992). <em>Ten Lectures on Wavelets</em></li>
<li>StÃ©phane Jaffard, Yves Meyer (1996). <em>Wavelet Methods for Pointwise Regularity</em></li>
</ul>
</section>
<section class="slide level1">

<h2 id="agradecimientos">Agradecimientos</h2>
<ul>
<li><strong>Autor Original:</strong> Yufan Zhuang et al.</li>
<li><strong>Framework:</strong> JAX/Flax (Google Research)</li>
<li><strong>Benchmark:</strong> Long Range Arena (Google)</li>
<li><strong>Universidad del Valle:</strong> Departamento de MatemÃ¡ticas</li>
</ul>
<h3 id="contacto">Contacto:</h3>
<p><strong>Presentador:</strong> [Tu Nombre]<br />
<strong>Email:</strong> [tu.email@univalle.edu.co]<br />
<strong>Departamento de MatemÃ¡ticas - Univalle</strong></p>
</section>
<section id="gracias" class="slide level1">
<h1>Â¡Gracias!</h1>
<h2 id="preguntas">Â¿Preguntas?</h2>
</section>
<section class="slide level1">

<h2 id="apÃ©ndice-a-detalles-de-implementaciÃ³n">ApÃ©ndice A: Detalles de ImplementaciÃ³n</h2>
<h3 id="configuraciÃ³n-experimental">ConfiguraciÃ³n Experimental:</h3>
<div class="sourceCode" id="cb16"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HiperparÃ¡metros Ã³ptimos (LRA)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">model</span><span class="kw">:</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">num_layers</span><span class="kw">:</span><span class="at"> </span><span class="dv">6</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">emb_dim</span><span class="kw">:</span><span class="at"> </span><span class="dv">256</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">num_heads</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">qkv_dim</span><span class="kw">:</span><span class="at"> </span><span class="dv">256</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">mlp_dim</span><span class="kw">:</span><span class="at"> </span><span class="dv">1024</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="at">  </span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="fu">wavelet</span><span class="kw">:</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">type</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;db2&quot;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">wlen</span><span class="kw">:</span><span class="at"> </span><span class="dv">32</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">level</span><span class="kw">:</span><span class="at"> </span><span class="dv">3</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">trainable</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="at">  </span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="fu">training</span><span class="kw">:</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">batch_size</span><span class="kw">:</span><span class="at"> </span><span class="dv">32</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">learning_rate</span><span class="kw">:</span><span class="at"> </span><span class="fl">1e-4</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">warmup_steps</span><span class="kw">:</span><span class="at"> </span><span class="dv">8000</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">optimizer</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;adamw&quot;</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">weight_decay</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.01</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">dropout</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.1</span></span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="apÃ©ndice-b-pseudocÃ³digo-completo">ApÃ©ndice B: PseudocÃ³digo Completo</h2>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> WavSpA_Forward(x, params):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">        x: (batch, length, dim)</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">        params: dict de parÃ¡metros</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">        output: (batch, length, dim)</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. NormalizaciÃ³n</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    x_norm <span class="op">=</span> LayerNorm(x)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. DescomposiciÃ³n Wavelet</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    coeffs <span class="op">=</span> []</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    current <span class="op">=</span> x_norm</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_levels):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        low, high <span class="op">=</span> wavelet_decompose(current, params[<span class="st">&#39;wavelet&#39;</span>])</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        coeffs.append(high)  <span class="co"># Detalles</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        current <span class="op">=</span> low        <span class="co"># AproximaciÃ³n</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    coeffs.append(current)   <span class="co"># Ãšltima aproximaciÃ³n</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. AtenciÃ³n Multi-Escala</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    attended <span class="op">=</span> []</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> level, coeff <span class="kw">in</span> <span class="bu">enumerate</span>(coeffs):</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        attn_out <span class="op">=</span> SelfAttention(coeff, </span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>                                 heads<span class="op">=</span>params[<span class="st">&#39;heads&#39;</span>],</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>                                 qkv_dim<span class="op">=</span>params[<span class="st">&#39;qkv_dim&#39;</span>])</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        attended.append(attn_out)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. ReconstrucciÃ³n</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    reconstructed <span class="op">=</span> attended[<span class="op">-</span><span class="dv">1</span>]  <span class="co"># Comenzar con aproximaciÃ³n</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_levels<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>        reconstructed <span class="op">=</span> wavelet_reconstruct(reconstructed, </span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>                                           attended[j],</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>                                           params[<span class="st">&#39;wavelet&#39;</span>])</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Residual</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x <span class="op">+</span> reconstructed</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. MLP</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    mlp_out <span class="op">=</span> MLP(LayerNorm(x))</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> x <span class="op">+</span> mlp_out</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span></code></pre></div>
</section>
<section class="slide level1">

<h2 id="apÃ©ndice-c-visualizaciones">ApÃ©ndice C: Visualizaciones</h2>
<h3 id="mapa-de-atenciÃ³n---transformer-vs-wavspa">Mapa de AtenciÃ³n - Transformer vs WavSpA</h3>
<pre><code>Transformer (L=1024):
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]  â† Matriz LÃ—L (1M elementos)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
...

WavSpA (L=1024, J=3):
Nivel 0: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] (1024 elementos)
Nivel 1: [â–ˆâ–ˆâ–ˆâ–ˆ]     (512 elementos)
Nivel 2: [â–ˆâ–ˆ]       (256 elementos)
Nivel 3: [â–ˆ]        (128 elementos)

Total: ~1920 elementos (52Ã— reducciÃ³n!)</code></pre>
</section>
<section class="slide level1">

<h2 id="apÃ©ndice-d-comparaciÃ³n-con-otras-arquitecturas">ApÃ©ndice D: ComparaciÃ³n con Otras Arquitecturas</h2>
<table>
<thead>
<tr class="header">
<th>Arquitectura</th>
<th>Complejidad</th>
<th>Memoria</th>
<th>Max Length</th>
<th>Pros</th>
<th>Contras</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Transformer</td>
<td>O(LÂ²D)</td>
<td>O(LÂ²)</td>
<td>4K</td>
<td>Expresivo</td>
<td>No escala</td>
</tr>
<tr class="even">
<td>Longformer</td>
<td>O(LwD)</td>
<td>O(Lw)</td>
<td>16K</td>
<td>Local eficiente</td>
<td>Pierde global</td>
</tr>
<tr class="odd">
<td>Linformer</td>
<td>O(LkD)</td>
<td>O(Lk)</td>
<td>8K</td>
<td>ProyecciÃ³n baja dim</td>
<td>Aprox. burda</td>
</tr>
<tr class="even">
<td>Performer</td>
<td>O(LDÂ²)</td>
<td>O(LD)</td>
<td>16K</td>
<td>Kernel trick</td>
<td>Aprox. softmax</td>
</tr>
<tr class="odd">
<td>BigBird</td>
<td>O(LwD)</td>
<td>O(Lw)</td>
<td>16K</td>
<td>Sparse hÃ­brido</td>
<td>Complejo</td>
</tr>
<tr class="even">
<td><strong>WavSpA</strong></td>
<td><strong>O(LDÂ²)</strong></td>
<td><strong>O(LD)</strong></td>
<td><strong>16K+</strong></td>
<td><strong>Multi-escala</strong></td>
<td><strong>Overhead wavelets</strong></td>
</tr>
</tbody>
</table>
</section>
<section class="slide level1">

<h2 id="apÃ©ndice-e-mÃ©tricas-adicionales">ApÃ©ndice E: MÃ©tricas Adicionales</h2>
<h3 id="uso-de-memoria-batch32-l4096">Uso de Memoria (batch=32, L=4096):</h3>
<table>
<thead>
<tr class="header">
<th>Modelo</th>
<th>Activaciones</th>
<th>ParÃ¡metros</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Transformer</td>
<td>8.4 GB</td>
<td>0.5 GB</td>
<td><strong>8.9 GB</strong></td>
</tr>
<tr class="even">
<td>WavSpA (J=3)</td>
<td>2.1 GB</td>
<td>0.52 GB</td>
<td><strong>2.62 GB</strong></td>
</tr>
</tbody>
</table>
<p><strong>ReducciÃ³n:</strong> 70% menos memoria</p>
<h3 id="throughput-tokenssegundo-gpu-a100">Throughput (tokens/segundo, GPU A100):</h3>
<table>
<thead>
<tr class="header">
<th>Longitud</th>
<th>Transformer</th>
<th>WavSpA</th>
<th>Mejora</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>512</td>
<td>48K</td>
<td>45K</td>
<td>0.94Ã—</td>
</tr>
<tr class="even">
<td>2048</td>
<td>8K</td>
<td>18K</td>
<td><strong>2.25Ã—</strong></td>
</tr>
<tr class="odd">
<td>8192</td>
<td>OOM</td>
<td>6K</td>
<td><strong>âˆ</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="fin-de-la-presentaciÃ³n" class="slide level1">
<h1>FIN DE LA PRESENTACIÃ“N</h1>
<p><strong>Archivo complementario:</strong> <code>wavspa_learn_comentado.py</code><br />
<strong>CÃ³digo de ejemplo:</strong> Ver <code>/examples/benchmark_simple.py</code><br />
<strong>Datasets:</strong> Instrucciones en README.md</p>
<p>Â¡Gracias por su atenciÃ³n! ğŸŒŠ</p>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//dist/reveal.js"></script>

  // reveal.js plugins
  <script src="https://unpkg.com/reveal.js@^4//plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
      
        // Push each slide change to the browser history
        history: true,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
